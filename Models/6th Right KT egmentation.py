# -*- coding: utf-8 -*-
"""Right_KT_Segmentation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WWJFOKxmqGgLq27I4vKcIvBMdABJuLtM
"""

pip install keras-unet

# -*- coding: utf-8 -*-
import seaborn as sns; sns.set(color_codes=True)  # visualization tool
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt 
import os

import statistics
import collections
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
from datetime import datetime
from datetime import date
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import (
                    MultinomialNB, 
                    GaussianNB, 
                    BernoulliNB
                    )
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.svm import (
                    SVC, 
                    NuSVC, 
                    LinearSVC
                    )
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing  import StandardScaler
from sklearn.decomposition import PCA
from sklearn import tree
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report,confusion_matrix

from IPython.display import display 
from xgboost import XGBClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.svm import SVC

import keras
from keras.models import Sequential , Model
from keras.layers import (
                        Dense,
                        Conv2D,
                        MaxPool2D,
                        Flatten,
                        Dropout,
                        MaxPooling2D,
                        Input,
                        Conv2DTranspose,
                        Concatenate,
                        BatchNormalization,
                        UpSampling2D,
                        AveragePooling2D,
                        GlobalAveragePooling2D,
                        Activation,
                        ZeroPadding2D
                        )
from keras.preprocessing.image import ImageDataGenerator
from keras.optimizers import Adam , SGD
from keras.layers.merge import concatenate
from keras.layers.advanced_activations import LeakyReLU
from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping
from keras import backend as K
from keras.utils.np_utils import to_categorical # convert to one-hot-encoding
import albumentations as A
from google.colab.patches import cv2_imshow as show
#from keras.utils import plot_model

from sklearn.metrics import classification_report,confusion_matrix
from PIL import Image
import tensorflow as tf
import glob
import random
import cv2
from random import shuffle
import itertools
import imutils

#!unzip sample_data/images_data.zip -d sample_data/

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

patient_info = drive.CreateFile({'id':"1cWmJm6-MPhhDMxhkBnQzMnANjVofmdG_"})
patient_info.GetContentFile("patient_info.csv")
patient_info = pd.read_csv("patient_info.csv")

patient_info["Tumor_type_label"]= patient_info["Tumor_Type"]
cleanup_nums = {
    "Segmentation_Right_Label" : {
                        'Upper ':'Upper',
                         'Lower ':'Lower' ,
                         'Lower  ':'Lower',
                        'Middle ':'Middle',
                        'Healthy ':'Healthy',
                        'Lower and Upper  ':'Lower'
                        },
    "Tumor_type_label":{'Null':None  , "Benign":0 , 'Malignant':1 }
}
patient_info = patient_info.replace(cleanup_nums)

del cleanup_nums

patient_info = patient_info[patient_info['Tumor_type_label'].notnull()]

patient_info = patient_info[patient_info['Patient_Num'] != 24]

patient_info.info()

patient_info.sample(5)

patient_info = patient_info[ patient_info [ 'Segmentation_Right_Label'] != 'Middle' ]

flg = patient_info['Segmentation_Right_Label'].value_counts()
display(flg)
fig = plt.figure(figsize =(15, 30))
plt.pie( flg , labels=flg.index , autopct='%1.1f%%', shadow=True, startangle=90 )
plt.title('Segmentation Right Label')
plt.show()

cleanup_nums = {
        "Segmentation_Right_Label":{ 
              "Upper":0,
               "Lower":1, 
               "Healthy":2, 
               "Undefined":3 
               }
}


patient_info = patient_info.replace(cleanup_nums)

del cleanup_nums

patient_info['Segmentation_Right_Label'].value_counts()

labels = { 0:"Upper", 1:"Lower" ,2:"Healthy" , 3:"Undefined" }

def crop_contour(image, plot=False):
    
    # Convert the image to grayscale, and blur it slightly
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.GaussianBlur(gray, (5, 5), 0)

    # Threshold the image, then perform a series of erosions +
    # dilations to remove any small regions of noise
    thresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
    thresh = cv2.erode(thresh, None, iterations=2)
    thresh = cv2.dilate(thresh, None, iterations=2)

    # Find contours in thresholded image, then grab the largest one
    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cnts = imutils.grab_contours(cnts)
    c = max(cnts, key=cv2.contourArea)
  
    # Find the extreme points
    extLeft = tuple(c[c[:, :, 0].argmin()][0])
    extRight = tuple(c[c[:, :, 0].argmax()][0])
    extTop = tuple(c[c[:, :, 1].argmin()][0])
    extBot = tuple(c[c[:, :, 1].argmax()][0])
    
    # crop new image out of the original image using the four extreme points (left, right, top, bottom)
    new_image = image[extTop[1]:extBot[1], extLeft[0]:extRight[0]]            

    if plot:
        plt.figure()

        plt.subplot(1, 2, 1)
        plt.imshow(image)
        
        plt.tick_params(axis='both', which='both', 
                        top=False, bottom=False, left=False, right=False,
                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)
        
        plt.title('Original Image')
        plt.subplot(1, 2, 2)
        plt.imshow(new_image)

        plt.tick_params(axis='both', which='both', 
                        top=False, bottom=False, left=False, right=False,
                        labelbottom=False, labeltop=False, labelleft=False, labelright=False)
        plt.title('Cropped Image')
        plt.show()

    return new_image

def get_data (data_dir , target ):
    X = list()
    y=list()
    img_size = 256
    for index, row in patient_info.iterrows():
        path = os.path.join(data_dir, str (row['Patient_Num']))
        label = row[target]
        for img in os.listdir(path):
            try:
                img_arr = cv2.imread(os.path.join(path, img))[...,::-1]
                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size   
                X.append(resized_arr)
                y.append(label)
            except Exception as e:
                print(e , row['Patient_Num'] )
    return X , y

X , y  = get_data("sample_data/Dalia_Data/", target = "Segmentation_Right_Label")

def albumentations_for_small_labels ( x : list , y : list , targets : list ,number_gen_for_img : int   ) : 

  if number_gen_for_img <= 0 :
      print("error please add numbner more than 0 .")
      return [] , [] 

  x_new = x.copy()
  y_new = y.copy()
  labels = { 0:"Upper", 1:"Lower" ,2:"Healthy" , 3:"Undefined" }
  transform = A.Compose([A.RandomBrightnessContrast(brightness_limit=1, contrast_limit=1, p=1.0),])

  for img , label in zip(x ,y ) :
    if labels[label] in targets : 
        for i  in range ( 1,number_gen_for_img + 1 ) :
            transformed = transform(image=img)['image']

            for z in range( i - 1 ) : 
                transformed = transform(image=transformed)['image']

            x_new.append(transformed)
            y_new.append(label)
    else:
      continue
  return x_new , y_new 

X_new , Y_new = albumentations_for_small_labels( X , y , ['Lower','Undefined'] , 1 )

for i in range (0) : 
    print ('ss')

dict(zip(list(y),[list(y).count(i) for i in list(y)]))

dict(zip(list(Y_new),[list(Y_new).count(i) for i in list(Y_new)]))

index_image = 1210
plt.figure(figsize = (5,5))
plt.imshow(X[index_image])
plt.title(labels[y[index_image]])
plt.show()

index_image = 1500 
plt.figure(figsize = (5,5))
plt.imshow(X[index_image])
plt.title(labels[y[index_image]])
plt.show()

index_image = 700 
plt.figure(figsize = (5,5))
plt.imshow(X[index_image])
plt.title(labels[y[index_image]])
plt.show()

index_image = 0
plt.figure(figsize = (5,5))
plt.imshow(X[index_image])
plt.title(labels[y[index_image]])
plt.show()

x_train, x_test, y_train, y_test = train_test_split(X_new, Y_new, test_size = 0.30)
x_test, x_val, y_test, y_val = train_test_split(x_test, y_test , test_size = 0.10)

print ("Number images for training : {}".format(len (x_train)))
print ("Number images for testing : {}".format(len (x_test)))
print ("Number images for Validation : {}".format(len (x_val)))

def data_prepare (X , y , folder_name , labels ) :
    path = "sample_data/{}".format(folder_name)
    if os.path.isdir(path):
      pass
    else:
      os.mkdir(path)

    # create folder for labels 
    for key , value in labels.items()  : 
        path = "sample_data/{}/{}".format(folder_name,value)
        if os.path.isdir(path):
          pass
        else:
          os.mkdir(path)

    if len (X) != len (y) : 
      print ("error size data X and y is not equal")
      return 

    for index , value in enumerate(y) : 
      im = Image.fromarray(X[index])
      path = "sample_data/{}/{}/{}.jpeg".format(folder_name,labels[value],str(index))
      im.save(path)
    return

!rm -r sample_data/train/ sample_data/test/ sample_data/validation/

data_prepare (X=x_train ,y=y_train ,folder_name="train", labels=labels )
data_prepare (X=x_test ,y=y_test ,folder_name="test", labels=labels )
data_prepare (X=x_val ,y=y_val ,folder_name="validation", labels=labels )

def delete_images(path, number):
  x=os.listdir(path)
  for i in range(number):
    os.remove(os.path.join(path,x[i]))

## Genration Images 

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

test_datagen = ImageDataGenerator(rescale = 1./255)

training_set = train_datagen.flow_from_directory('/content/sample_data/train',
                                                 target_size = (224, 224),
                                                 batch_size = 32,
                                                 class_mode = 'categorical')

test_set = test_datagen.flow_from_directory('/content/sample_data/test',
                                            target_size = (224,224),
                                            batch_size = 32,
                                            class_mode = 'categorical')

model= Sequential()
model.add(Conv2D(32, (3, 3), input_shape = (224, 224, 3), activation = 'relu'))
model.add(Flatten())
model.add(Dense(units = 128, activation = 'relu'))
model.add(Dense(units = 4 , activation = 'softmax'))
opt = keras.optimizers.Adam(learning_rate=0.00001)
model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=["accuracy"])


# class AccuracyStopping(keras.callbacks.Callback):
#     def __init__(self, acc_threshold):
#         super(AccuracyStopping, self).__init__()
#         self._acc_threshold = acc_threshold

#     def on_epoch_end(self, batch, logs={}):
#         train_acc = logs.get('accuracy')
#         print(train_acc)
#         value=1-train_acc
#         print(value)
#         self.model.stop_training = value <= self._acc_threshold

# acc_callback = AccuracyStopping(0.02)

# def get_Model():
#     modelName= Sequential()
#     modelName.add(BatchNormalization(input_shape = (224,224,3)))
#     modelName.add(Conv2D(32, (3, 3), input_shape = (224, 224, 3), activation = 'relu'))
#     modelName.add(MaxPooling2D(pool_size = (2, 2)))
#     modelName.add(Dropout(0.25))
#     modelName.add(Flatten())
#     modelName.add(Dense(units = 128, activation = 'relu'))
#     modelName.add(Dense(units = 4 , activation = 'softmax'))
#     return modelName

# model=get_Model()

# model.compile( 
#               optimizer='adam' , 
#               loss ="categorical_crossentropy", 
#               metrics=['accuracy']    
#               )

model.summary()
training_set.class_indices
test_set.class_indices

history = model.fit(
                training_set,
                steps_per_epoch = (3528 /32),
                epochs=30, 
                validation_data=test_set,
                validation_steps = (1360 /32)
                )

loss,accuracy=model.evaluate(test_set)
print (f"Test Loss     = {loss}")
print (f"Test Accuracy = {accuracy}")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

plt.figure(figsize=(15, 15))

fig, ax = plt.subplots(figsize = (15 ,15) , dpi=80,)
ax.set_facecolor('#ffffff')
ax.xaxis.label.set_color('#000000')
ax.yaxis.label.set_color('#000000')
ax.tick_params(axis='x', colors='#000000' )  
ax.tick_params(axis='y', colors='#000000')
ax.spines['left'].set_color('#000000')  
ax.spines['bottom'].set_color('#000000')

plt.subplot(2, 2, 1)
plt.plot( acc, label='Training Accuracy')
plt.plot( val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 2, 2)
plt.plot( loss, label='Training Loss')
plt.plot( val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

print('Training Set Clases')
print(training_set.class_indices)
print("=="*10)
print('Testing Set Clases')
print(test_set.class_indices)

labels = { 0:"Healthy",1:"Lower",2:"Undefined",3:"Upper" }

from keras.preprocessing import image
label_0 = labels[0]
path='/content/sample_data/validation/{}'.format(label_0)
l_0 =[]

filelist= [file for file in os.listdir(path) if file.endswith('.jpeg')]
y_0 =[0]*len(filelist)
print ("Number of images for {} :".format(label_0) , len (filelist))

for img in filelist:
  test_image = image.load_img(os.path.join(path, img),target_size = (224, 224))
  test_image = image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  l_0.append(test_image)

l_0_result=[]
for i in range(len(l_0)):
  xx = model.predict_classes(l_0[i])
  l_0_result.append(xx)

l_0_draw= list ()
for i in l_0_result:
    l_0_draw.append(labels[i[0]])

display('==='*10)
display(dict(zip(list(l_0_draw),[list(l_0_draw).count(i) for i in list(l_0_draw)])))
display('==='*10)

sns.set_style('darkgrid')
sns.countplot(l_0_draw)
plt.show()

print('testing accuracy for {} class is {}'.format(1.0-((list(l_0_draw).count('Upper')/len(y_0))*1)))

from keras.preprocessing import image
label_1 = labels[1]
path='/content/sample_data/validation/{}'.format(label_1)
l_1 =[]

filelist= [file for file in os.listdir(path) if file.endswith('.jpeg')]
y_1 =[1]*len(filelist)
print ("Number of images for {} :".format(label_1) , len (filelist))

for img in filelist:
  test_image = image.load_img(os.path.join(path, img),target_size = (224, 224))
  test_image = image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  l_1.append(test_image)
print(len(l_1))
l_1_result=[]
for i in range(len(l_1)):
  xx = model.predict_classes(l_1[i])
  l_1_result.append(xx)

l_1_draw= list ()
for i in l_1_result:
    l_1_draw.append(labels[i[0]])

display('==='*10)
display(dict(zip(list(l_1_draw),[list(l_1_draw).count(i) for i in list(l_1_draw)])))
display('==='*10)

sns.set_style('darkgrid')
sns.countplot(l_1_draw)
plt.show()

print('testing accuracy for Lower class is {}'.format(1.0-((list(l_1_draw).count('Lower')/len(y_1))*1)))

from keras.preprocessing import image
label_2 = labels[2]
path='/content/sample_data/validation/{}'.format(label_2)
l_2 =[]

filelist= [file for file in os.listdir(path) if file.endswith('.jpeg')]
y_2 =[2]*len(filelist)
print ("Number of images for {} :".format(label_2) , len (filelist))

for img in filelist:
  test_image = image.load_img(os.path.join(path, img),target_size = (224, 224))
  test_image = image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  l_2.append(test_image)

l_2_result=[]
for i in range(len(l_2)):
  xx = model.predict_classes(l_2[i])
  l_2_result.append(xx)

l_2_draw= list ()
for i in l_2_result:
    l_2_draw.append(labels[i[0]])

display('==='*10)
display(dict(zip(list(l_2_draw),[list(l_2_draw).count(i) for i in list(l_2_draw)])))
display('==='*10)

sns.set_style('darkgrid')
sns.countplot(l_2_draw)
plt.show()

print('testing accuracy for Middle class is {}'.format(1.0-((list(l_2_draw).count('Middle')/len(y_2))*1)))

from keras.preprocessing import image
label_3 = labels[3]
path='/content/sample_data/validation/{}'.format(label_3)
l_3 =[]

filelist= [file for file in os.listdir(path) if file.endswith('.jpeg')]
y_3 =[3]*len(filelist)
print ("Number of images for {} :".format(label_3) , len (filelist))

for img in filelist:
  test_image = image.load_img(os.path.join(path, img),target_size = (224, 224))
  test_image = image.img_to_array(test_image)
  test_image = np.expand_dims(test_image, axis = 0)
  l_3.append(test_image)

l_3_result=[]
for i in range(len(l_3)):
  xx = model.predict_classes(l_3[i])
  l_3_result.append(xx)

l_3_draw= list ()
for i in l_3_result:
    l_3_draw.append(labels[i[0]])

display('==='*10)
display(dict(zip(list(l_3_draw),[list(l_3_draw).count(i) for i in list(l_3_draw)])))
display('==='*10)

sns.set_style('darkgrid')
sns.countplot(l_3_draw)
plt.show()

from sklearn.metrics import roc_auc_score
from sklearn.metrics import roc_curve, auc

print('Training Set Clases')
print(training_set.class_indices)
print('Testing Set Clases')
print(test_set.class_indices)
print("====="*10)
print('\nConfusion Matrix')
print('Classification Report')
target_names = ['Healthy',"Lower",'Undefined',"Upper"]

y_labels  = y_0 +y_1+y_2+y_3
x_results = l_0_result + l_1_result + l_2_result + l_3_result 
print(classification_report( y_labels , x_results , target_names=target_names))